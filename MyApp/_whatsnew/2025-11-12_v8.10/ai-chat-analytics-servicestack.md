---
title: FREE Gemini, Minimax, GLM 4.6, Kimi K2 in AI Chat
url: https://docs.servicestack.net/ai-chat-analytics
image: /img/whatsnew/v8.10/ai-chat-servicestack.webp
order: 4
---

ServiceStack now offers FREE access to premium AI models through the new `servicestack` OpenAI Chat provider. Get instant access to Google's Gemini Flash, Kimi K2 (with thinking mode), Minimax M2, GLM 4.6, and top open-source models including Llama 4 400B and Mistral Small 3.2—all without API keys or cloud accounts.

The lightweight AI Chat integration provides a unified provider abstraction through simple `llms.json` configuration, enabling seamless switching between providers without code changes. Mix local and cloud models, optimize for cost or performance, and ensure reliability with automatic failover—all with zero heavy dependencies.

Integration is effortless with the `IChatClient` dependency, supporting text, image, audio, and document inputs across compatible models. Free for personal use and development with a generous 60 requests/hour limit (replenishing at 1 request per minute). Requires any ServiceStack license key, including free or expired licenses.
