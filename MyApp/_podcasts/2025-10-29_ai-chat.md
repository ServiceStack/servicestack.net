---
title: AI Chat - A Simple OpenAI Chat Completions API, UI & Client LLM Gateway
summary: Unlock the value of OpenAI Chat APIs using a simple, serializable ChatCompletion DTO that works everywhere
tags: [llms,ai,openai,chat]
author: Demis Bellot
url: https://media.servicestack.com/podcasts/apikey_auth_apis.mp3
media: {size:13193573,duration:950.256327,format:mp3}
---

This episode introduces **AI Chat**, a new solution designed to simplify the integration of AI into applications 
by focusing entirely on the **OpenAI Chat Completion API**. This approach prioritizes a simple, serializable
`ChatCompletion` **Data Transfer Object (DTO)** which acts as the core abstraction, contrasting sharply 
with overly complex frameworks like **Microsoft Semantic Kernel**. 

It's argues that heavyweight, non-portable abstractions quickly become irrelevant as AI models advance, 
leading to vendor lock-in and required rewrites. By centering the design around the `ChatCompletion` DTO, 
**ServiceStack.AI.Chat** offers advantages like easy data persistence, client-side usability, and 
simplified debugging, while also supporting multi-modal content like images and audio. 

The solution includes robust **model routing and failover** capabilities configured via a simple `llms.json` file, 
and is compatible with its Python counterpart, [llms.py](https://github.com/ServiceStack/llms).